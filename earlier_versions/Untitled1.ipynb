{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Project to make plots of hurricane seasons, \n",
    "#like the ones on Wikipedia but showing what category the storm was at a specific time. \n",
    "#This could be part of a broader hurricane visualization effort."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Need to import the data from the NHC's HURDAT2 archive\n",
    "#Comma delimited. \n",
    "#Each storm starts with a line containing an 8-letter code (e.g. AL182017), the name of the storm (e.g. Philippe), and the number of advisories. \n",
    "#Then for each advisory there are a bunch of numbers separated by commas:\n",
    "#Date (YYYYMMDD)\n",
    "#Time (UTC) (HHMM, e.g. 1800)\n",
    "#Whether advisory is at standard time (blank if yes, otherwise I or L)\n",
    "#Storm type (LO, TD, TS, HU, EX)\n",
    "#Latitude of center (##.#N)\n",
    "#Longitude of center (##.#W)\n",
    "#Max winds (knots) (2 or 3 digit integer)\n",
    "#Minimum central pressure (mb) (3 or 4 digit integer)\n",
    "#12 lines for size of wind field. I believe these are TS, 50 knot and hurricane wind fields, \n",
    "# but not sure how the quadrants are ordered. \n",
    "\n",
    "#For the timelines all I need is the advisory times and the max winds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#So just parsing the data is going to be a challenge by itself. \n",
    "#If I could have a DataFrame or XArray dataset for each storm, that would be ideal. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Load dataframe from csv file (with header added automatically)\n",
    "df = pd.read_csv('hurdat2-1851-2017-050118_withHeader.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Amazingly, read_csv already was able to parse the headers and... \n",
    "#Well, not really, just have the entire table loaded. \n",
    "#Need to split it up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Better dataframe now with column names that I added manually. But still need to access individual storms. \n",
    "#Could create a Storm object that wraps DataFrame and has a few extra variables, for identifier, name, and number of advisories?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Other strategies I could use: write a script to separate all the hurricanes into different files?\n",
    "#Basically loop through each line, put identifier and storm name in the file name. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = open('hurdat2-1851-2017-050118_withHeader.txt')\n",
    "lines = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lines[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lines[1][0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lines[1].split(',')[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lines[1].split(',')[1].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'AL' == 'A'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(lines)):\n",
    "    line = lines[i]\n",
    "    if line[0:2] == 'AL': #This line denotes a storm\n",
    "        stormIdentifier = line.split(',')[0] #No whitespace\n",
    "        stormName = line.split(',')[1].strip() #Get rid of whitespace\n",
    "        numLinesForStorm = int(line.split(',')[2])\n",
    "        #Create a file and add lines to it for all the advisories\n",
    "        with open(stormIdentifier+'_'+stormName+'.txt', 'w') as g:\n",
    "            for j in range(i:i+numLinesForStorm):\n",
    "                g.write(lines[j])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
